
```markdown
# MISSION: REWRITE RLSIM ARCHITECTURE FROM CPU-OOP TO GPU-JAX-PURE

**ROLE:** You are a World-Class High-Performance Computing Engineer and JAX/XLA Specialist. You do not write "Python scripts"; you write "numerical kernels".

**OBJECTIVE:**
I have this codebase (`RLSim`) which is currently a C++ CPU-based simulation wrapped in Python. It uses OOP, pointers, and serial execution.
Your task is to IGNORE the architectural patterns of this code and **re-implement the core physics logic using JAX** to run natively on GPU.

We are NOT porting the code. We are **transplanting the logic** into a JAX-compatible mathematical framework.

---

## ðŸ›‘ THE COMMANDMENTS (STRICT CONSTRAINTS)

1.  **NO OBJECT-ORIENTED PHYSICS:**
    * Forbidden: `class Car`, `class Ball`, `car.update()`.
    * Required: `GameState` (NamedTuple/PyTree) containing `(N_ENVS, ...)` tensors.
    * State must be a "Struct of Arrays" (SoA), not "Array of Structs".

2.  **THE "PURE FUNCTION" RULE:**
    * The entire simulation step must be a single pure function: `next_state = step(current_state, actions)`.
    * No side effects. No global variables. No mutations in place.

3.  **SHAPE STABILITY IS LAW:**
    * All tensor shapes must be static and known at compile time (JIT).
    * Use `N_ENVS` as the batch dimension (0).
    * **Forbidden:** `list.append`, dynamic masking that changes shapes, `if` statements that depend on data values.
    * **Required:** `jnp.where` (masking), `lax.cond`, `lax.scan`.

4.  **ZERO CPU TRANSFER:**
    * The data must live on VRAM.
    * Do not convert to NumPy (`np.array`) inside the loop. Stay in `jax.numpy` (`jnp`).

5.  **COLLISION LOGIC:**
    * Do not use conditional branching for collisions (e.g., `if dist < radius`).
    * Calculate physics for *all* pairs, then apply `jnp.where(is_colliding, new_vel, old_vel)`.
    * Yes, this wastes FLOPs on non-colliding objects. That is intended. Divergence is worse than wasted math.
 